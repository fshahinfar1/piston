Running experiment with pipeline mode: simple
Processing a pile of 64 requests
Batch size is: 3
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 86 size: 404627504
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 85 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 84 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 83 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 82 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 81 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 80 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 79 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 78 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 77 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 76 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 75 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 74 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 73 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 72 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 71 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 70 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 69 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 68 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 67 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 66 size: 1217421528
---> num layers: 32 num floats: 9510912 shape: torch.Size([3, 32, 1032, 96])
Req 65 size: 1217421528
Time to process 64 requests: 1047.56 seconds
