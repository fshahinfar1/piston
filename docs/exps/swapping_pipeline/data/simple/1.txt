Running experiment with pipeline mode: simple
Processing a pile of 64 requests
Batch size is: 1
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 128 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 127 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 126 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 125 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 124 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 123 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 122 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 121 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 120 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 119 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 118 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 117 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 116 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 115 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 114 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 113 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 112 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 111 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 110 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 109 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 108 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 107 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 106 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 105 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 104 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 103 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 102 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 101 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 100 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 99 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 98 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 97 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 96 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 95 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 94 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 93 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 92 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 91 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 90 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 89 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 88 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 87 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 86 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 85 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 84 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 83 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 82 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 81 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 80 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 79 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 78 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 77 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 76 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 75 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 74 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 73 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 72 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 71 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 70 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 69 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 68 size: 404627504
---> num layers: 32 num floats: 3170304 shape: torch.Size([1, 32, 1032, 96])
Req 67 size: 405807176
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 66 size: 404627504
---> num layers: 32 num floats: 3161088 shape: torch.Size([1, 32, 1029, 96])
Req 65 size: 404627504
Time to process 64 requests: 2380.93 seconds
