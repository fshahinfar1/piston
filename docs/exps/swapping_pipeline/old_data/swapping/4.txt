Running experiment with pipeline mode: swapping
Processing a pile of 64 requests
Batch size is: 4
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 80 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 79 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 78 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 77 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 76 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 75 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 74 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 73 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 72 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 71 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 70 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 69 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 68 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 67 size: 1623228704
---> num layers: 32 num floats: 12693504 shape: torch.Size([4, 32, 1033, 96])
Req 66 size: 1624015136
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 65 size: 1623228704
Time to process 64 requests: 446.94 seconds
