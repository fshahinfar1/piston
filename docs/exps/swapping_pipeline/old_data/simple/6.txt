Running experiment with pipeline mode: simple
Processing a pile of 64 requests
Batch size is: 6
---> num layers: 32 num floats: 12681216 shape: torch.Size([4, 32, 1032, 96])
Req 75 size: 1623228704
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 74 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 73 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 72 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 71 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 70 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 69 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 68 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 67 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 66 size: 2434843056
---> num layers: 32 num floats: 19021824 shape: torch.Size([6, 32, 1032, 96])
Req 65 size: 2434843056
Time to process 64 requests: 616.84 seconds
